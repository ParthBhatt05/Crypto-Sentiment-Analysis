{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Vader and Text Blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:44:35.308109Z",
     "start_time": "2021-08-16T12:44:27.643370Z"
    }
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis has two approaches : \n",
    "1. Polarity-based which provides the result as 'positive' (1), 'negative' (-1) and 'neutral' (0) as the output.\n",
    "2. Valence-based which uses lexicon to provide ratings or weigtage to sentiment words and provides four scores : pos,neg,neu and compound.\n",
    "*(Compound is final score which is the sum of all the lexicon ratings and is standardised to range between -1 or 1)*\n",
    "\n",
    "#### Below are some examples of how both works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER : *V*alence *A*ware *D*ictionary for S*e*ntiment *R*easoning\n",
    "\n",
    "---\n",
    "- Vader is one of the approach to perform Sentiment analysis for a given text and results 'positive', 'negative','neutral' and 'compound' ratings.\n",
    "- Vader is lexicon-based (dictionary-based) sentiment analysis approach.\n",
    "- Unlike polarity based analysis where for example, says excellent and good have positive sentiment but in Vader it would say excellent has higher positive rating than good, lets say 1.9 and 1.8 positive score respectively. The advantage of such analysis proves to provide a precise resultant sentiment rating.\n",
    "- Compound score is sum of all lexicon ratings which has been standardised to a range between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:44:37.384017Z",
     "start_time": "2021-08-16T12:44:37.378006Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence1 = \"The Bitcoin price has gone UP, time to SELL :)\" # HIGH POSITIVE\n",
    "sentence2 = \"WOW!!! There is a Sale in the nearby shopping centre.\" # POSITIVE to NEUTRAL\n",
    "sentence3 = 'The Airline XYZ is horrible, got delayed and OMG no apologies from the staff.' # HIGH NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:44:41.432782Z",
     "start_time": "2021-08-16T12:44:41.411370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the packages for Vader sentiment analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:45:06.477698Z",
     "start_time": "2021-08-16T12:45:06.469699Z"
    }
   },
   "outputs": [],
   "source": [
    "def vd_sentiment_scores(sentence):\n",
    "    snt = analyzer.polarity_scores(sentence)\n",
    "    print(str(snt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:45:08.452851Z",
     "start_time": "2021-08-16T12:45:08.439850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.75, 'pos': 0.25, 'compound': 0.4588}\n",
      "None\n",
      "\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.7513}\n",
      "None\n",
      "\n",
      "{'neg': 0.409, 'neu': 0.591, 'pos': 0.0, 'compound': -0.765}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vd_sentiment_scores(sentence1))\n",
    "print('')\n",
    "print(vd_sentiment_scores(sentence2))\n",
    "print('')\n",
    "print(vd_sentiment_scores(sentence3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis using Text blob\n",
    "\n",
    "- TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "- TextBlob can do more than text analysis like language translation, Part-of-speech tagging, Tokenization (splitting text into words and sentences) etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:45:13.730004Z",
     "start_time": "2021-08-16T12:45:13.719023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the packages for Textblob sentiment analysis\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:45:15.392467Z",
     "start_time": "2021-08-16T12:45:15.374469Z"
    }
   },
   "outputs": [],
   "source": [
    "def tb_analyze_sentiment(text):\n",
    "        analysis = TextBlob(text)\n",
    "        #sentiment= None\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive: ' + str(analysis.sentiment.polarity)\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral: ' + str(analysis.sentiment.polarity)\n",
    "        else:\n",
    "            return 'negative: ' + str(analysis.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T12:45:17.244725Z",
     "start_time": "2021-08-16T12:45:17.208725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: 0.5\n",
      "\n",
      "positive: 0.1953125\n",
      "\n",
      "negative: -1.0\n"
     ]
    }
   ],
   "source": [
    "print(tb_analyze_sentiment(sentence1))\n",
    "print()\n",
    "print(tb_analyze_sentiment(sentence2))\n",
    "print()\n",
    "print(tb_analyze_sentiment(sentence3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both ouputs are giving similar results but little surpised by VADER, giving sentence 1 as not that High positive, inspite having a capital and happy emoticon in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Vader sentiment analysis would give a comparative precise sentiment analysis of the Twitter data than Text blob.\n",
    "- Also, taking into consideration that the data isn't clean but Vader works well with exclaimation, emoticon, captilisation than TextBlob. Hence, I would repeat this after the data cleaning process."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
